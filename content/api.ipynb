{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6faf5a-c6b9-46d4-ae6a-af75bb13940b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T19:12:31.801910Z",
     "iopub.status.busy": "2024-10-22T19:12:31.801643Z",
     "iopub.status.idle": "2024-10-22T19:12:31.809340Z",
     "shell.execute_reply": "2024-10-22T19:12:31.808256Z",
     "shell.execute_reply.started": "2024-10-22T19:12:31.801886Z"
    }
   },
   "source": [
    "# Playing with LLM APIs\n",
    "\n",
    "In this notebook, we will use large language models (LLMs) through an API. Most LLM providers offer an API to use their LLMs programmatically (for instance, with Python).\n",
    "\n",
    "[Groq](https://groq.com/) freely provides (as of October 2024) access to some open LLMs, like Llama from Meta or Mixtral from Mistral AI.\n",
    "\n",
    "## Get credentials and API key\n",
    "\n",
    "- Create a free account on Groq: <https://console.groq.com/login>\n",
    "\n",
    "  You can use your GitHub or Google account for authenication.\n",
    "- Then go on [Groq's API keys](https://console.groq.com/keys) page\n",
    "- Click the black button  \"Create API Key\"\n",
    "- Chose a name for your key.\n",
    "- Copy your API key and paste it somewhere. For security reason, your API key won't be shown again. Your API key should look like: `gsk_W1Jz47u5ieJs28D8m...`\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56268464-22c3-4d87-a668-0806599932cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T19:13:14.846207Z",
     "iopub.status.busy": "2024-10-22T19:13:14.845781Z",
     "iopub.status.idle": "2024-10-22T19:13:14.853229Z",
     "shell.execute_reply": "2024-10-22T19:13:14.852345Z",
     "shell.execute_reply.started": "2024-10-22T19:13:14.846170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "From university computers, use the Conda environment `ppoulain-llm-24`:\n",
       "\n",
       "```bash\n",
       "$ conda activate ppoulain-llm-24\n",
       "```\n",
       "\n",
       "You can also try to create this environement on your own computer.\n",
       "\n",
       "Either with [Miniconda](https://docs.anaconda.com/miniconda/):\n",
       "\n",
       "```bash\n",
       "$ mkdir -p llm-practicals\n",
       "$ cd llm-practicals\n",
       "$ curl https://raw.githubusercontent.com/pierrepo/llm-practicals/main/content/practical-env.yml --output practical-env.yml\n",
       "# or wget https://raw.githubusercontent.com/pierrepo/llm-practicals/main/content/practical-env.yml\n",
       "$ conda env create -f practical-env.yml\n",
       "$ conda activate ppoulain-llm-24\n",
       "$ jupyter lab\n",
       "```\n",
       "\n",
       "or with [Pixi](https://pixi.sh):\n",
       "\n",
       "```bash\n",
       "$ mkdir -p llm-practicals\n",
       "$ cd llm-practicals\n",
       "$ curl https://raw.githubusercontent.com/pierrepo/llm-practicals/main/content/practical-env.yml --output practical-env.yml\n",
       "# or wget https://raw.githubusercontent.com/pierrepo/llm-practicals/main/content/practical-env.yml\n",
       "$ pixi init --import practical-env.yml\n",
       "$ pixi run jupyter lab\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display; display(Markdown(\"env_instructions.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7e69a-a7f1-4b49-814f-72da5f3b0c28",
   "metadata": {},
   "source": [
    "## Use Groq's API\n",
    "\n",
    "Declare your API key with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4669842d-a75a-45d4-b725-500e5f175b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T19:36:08.312086Z",
     "iopub.status.busy": "2024-10-22T19:36:08.311430Z",
     "iopub.status.idle": "2024-10-22T19:36:08.319615Z",
     "shell.execute_reply": "2024-10-22T19:36:08.318312Z",
     "shell.execute_reply.started": "2024-10-22T19:36:08.312016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"YOUR-API-KEY-HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ba0bd-faa7-448c-bc82-44982264463b",
   "metadata": {},
   "source": [
    "Replace `YOUR-API-KEY-HERE` with your real Groq API key.\n",
    "\n",
    "Then, you can send your first prompt to a Llama LLM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c39b7131-fa7a-4010-8ed8-2068e3732b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T20:07:38.907885Z",
     "iopub.status.busy": "2024-10-22T20:07:38.907569Z",
     "iopub.status.idle": "2024-10-22T20:07:39.287184Z",
     "shell.execute_reply": "2024-10-22T20:07:39.286531Z",
     "shell.execute_reply.started": "2024-10-22T20:07:38.907864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Hey there!\n",
      "\n",
      "So, you know how scientists study living things like animals, plants, and even tiny germs to understand how they work and what makes them special? Well, bioinformatics is like doing the same thing, but for the \"instructions\" or software that tells our bodies how to grow and work properly. \n",
      "\n",
      "Instead of using microscopes or test tubes, bioinformaticians use computers and special programs to study these instructions, called genes. They try to figure out how genes work together to make us who we are, and how they might help us understand and treat diseases.\n",
      "\n",
      "Think of it like playing a super complex video game, where the genes are like the game's code, and the scientists are trying to figure out how to \"beat the level\" to make new discoveries and help people!\n",
      "\n",
      "Does that make sense?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "def chat(question, model):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[ {\"role\": \"user\", \"content\": question} ],\n",
    "        model=model,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "\n",
    "print(\n",
    "    \"=\"*50,\n",
    "    chat(\n",
    "        \"Explain in a short text what is bioinformatics to a middle school student\",\n",
    "        \"llama3-8b-8192\"\n",
    "    ),\n",
    "    \"=\"*50,\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da16e9e-74eb-4d5e-b34b-8efb412320ab",
   "metadata": {},
   "source": [
    "Look at [available LLM models in Groq](https://console.groq.com/docs/models) and try with two different models. \n",
    "\n",
    "```{warning}\n",
    "Be sure to select a LLM that works with chat. For instance, `distil-whisper-large-v3-en` is not a chat model.\n",
    "```\n",
    "\n",
    "Here is another example with `llama-3.2-3b-preview`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0b5c09c-2689-42fc-a14a-36c388a21568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T20:38:10.474234Z",
     "iopub.status.busy": "2024-10-22T20:38:10.473924Z",
     "iopub.status.idle": "2024-10-22T20:38:10.915371Z",
     "shell.execute_reply": "2024-10-22T20:38:10.914862Z",
     "shell.execute_reply.started": "2024-10-22T20:38:10.474208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Bioinformatics is like being a scientist detective. Imagine you have a huge box full of information about living things, like their DNA, genes, and how they work. But, this information is too much to handle by itself.\n",
      "\n",
      "A bioinformatics scientist is like a super smart librarian who helps organize and analyze all this information using special computer science skills. They use computers and math to:\n",
      "\n",
      "* Read and understand the genetic code (which is like a secret code in the DNA)\n",
      "* Find patterns and connections between different things in the data\n",
      "* Create maps and graphs to help us understand how living things are related\n",
      "* Even make predictions about how things will work\n",
      "\n",
      "By using computers and math to analyze biological data, bioinformatics scientists can help us:\n",
      "\n",
      "* Find new medicines\n",
      "* Understand how diseases work\n",
      "* Help keep our environment healthy\n",
      "\n",
      "It's a really cool job that combines science, math, and computers to help us learn more about the amazing world of living things!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"=\"*50,\n",
    "    chat(\n",
    "        \"Explain in a short text what is bioinformatics to a middle school student\",\n",
    "        \"llama-3.2-3b-preview\"\n",
    "    ),\n",
    "    \"=\"*50,\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eee39d-ab5d-49cd-89e6-5d7b63d13718",
   "metadata": {},
   "source": [
    "## Are LLMs good at math?\n",
    "\n",
    "> Spoiler: no!\n",
    "\n",
    "In the following, we will assess the performance of a LLM in simple math calculations.\n",
    "\n",
    "### Find the correct prompt\n",
    "\n",
    "Design a prompt that forces the LLM to output only the result of the product of two integers. Test your prompt with several time with different integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f6c4d81-1899-469d-86c3-6a4d33538000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T20:07:54.512905Z",
     "iopub.status.busy": "2024-10-22T20:07:54.512259Z",
     "iopub.status.idle": "2024-10-22T20:07:54.830832Z",
     "shell.execute_reply": "2024-10-22T20:07:54.829970Z",
     "shell.execute_reply.started": "2024-10-22T20:07:54.512864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Design a theme park for a generation of time travelers, where attractions, restaurants, and shops are all centered around different eras and cultures from history. What would you name this park, and what\\'s the main event of the year there?\"'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    \"YOUR-CLEVER-PROMPT-HERE\",\n",
    "    \"llama-3.2-3b-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778ea66-cab8-4fbf-b133-6e9e2a79c397",
   "metadata": {},
   "source": [
    "## LLM vs Python\n",
    "\n",
    "In the following code, we ask several times a LLM the result of the product of two integers and compare the output to the correct answer provided by Python.\n",
    "\n",
    "Take some time to understand how the code works.\n",
    "\n",
    "Run the code, play with it and make some improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce8aeda1-9893-491b-9dca-4bab52ff0ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T20:41:16.581132Z",
     "iopub.status.busy": "2024-10-22T20:41:16.580837Z",
     "iopub.status.idle": "2024-10-22T20:41:21.015496Z",
     "shell.execute_reply": "2024-10-22T20:41:21.012314Z",
     "shell.execute_reply.started": "2024-10-22T20:41:16.581106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 x 91 = 7098 | 7098 OK\n",
      "98 x 88 = 8624 | 8656 Wrong!\n",
      "62 x 31 = 1922 | 1912 Wrong!\n",
      "45 x 59 = 2655 | 2655 OK\n",
      "92 x 81 = 7452 | 7432 Wrong!\n",
      "65 x 45 = 2925 | 2925 OK\n",
      "29 x 13 = 377 | 373 Wrong!\n",
      "72 x 80 = 5760 | 5760 OK\n",
      "92 x 98 = 9016 | 9044 Wrong!\n",
      "65 x 63 = 4095 | 4105 Wrong!\n",
      "11 x 65 = 715 | 715 OK\n",
      "55 x 14 = 770 | 770 OK\n",
      "90 x 37 = 3330 | 3330 OK\n",
      "88 x 26 = 2288 | 2288 OK\n",
      "57 x 47 = 2679 | 2669 Wrong!\n",
      "45 x 19 = 855 | 855 OK\n",
      "43 x 95 = 4085 | 4095 Wrong!\n",
      "48 x 84 = 4032 | 4032 OK\n",
      "42 x 57 = 2394 | 2394 OK\n",
      "24 x 85 = 2040 | 2040 OK\n",
      "Success rate: 60%\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "correct_answers = 0\n",
    "total_attempts = 20\n",
    "\n",
    "for _ in range(total_attempts):\n",
    "    number_1 = randint(10, 100)\n",
    "    number_2 = randint(10, 100)\n",
    "    llm_result = chat(\n",
    "        f\"What is the result of {number_1} times {number_2}. Only reply with the result\",\n",
    "        \"llama3-8b-8192\"\n",
    "    )\n",
    "    # Remove extra characters from LLM output.\n",
    "    llm_result = llm_result.replace(\",\", \"\").replace(\".\", \"\")\n",
    "    # Get Python result.\n",
    "    python_result = number_1 * number_2\n",
    "    print(f\"{number_1} x {number_2} = {python_result} | {llm_result} \", end=\"\")\n",
    "    # Check result.\n",
    "    if llm_result == str(python_result):\n",
    "        correct_answers += 1\n",
    "        print(f\"OK\")\n",
    "    else:\n",
    "        print(f\"Wrong!\")\n",
    "\n",
    "print(f\"Success rate: {correct_answers/total_attempts:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b329543-70f8-4f3a-92c6-4e421d490698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
