{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcc70a2-016f-442c-a129-4a3d0c90551c",
   "metadata": {},
   "source": [
    "# Embeddings with Python\n",
    "\n",
    "## Setup\n",
    "\n",
    "Please check you have configured your environement properly with uv (see [setup](../setup.md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7502c-e120-474f-93f3-06c26ea20f82",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f03955-92e8-4ec8-9520-193b4dfccabd",
   "metadata": {},
   "source": [
    "[sentence-transformers](https://github.com/UKPLab/sentence-transformers) is a Python library for computing sentence embeddings. This library works fully locally but requires an internet connection to download embedding models.\n",
    "\n",
    "The documentation is available [here](https://www.sbert.net/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a372898-b938-4d77-8be5-045db83f9ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/workp/teaching/BI_M2_LLM/llm-practicals.git/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f29fe-1d98-4b60-9e51-c93f60f97179",
   "metadata": {},
   "source": [
    "*The warning message in red is OK.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08c06e-33c1-4e16-82c5-e716e250e896",
   "metadata": {},
   "source": [
    "### (Down)Load model\n",
    "\n",
    "We load the [all-mpnet-base-v2]((https://huggingface.co/sentence-transformers/all-mpnet-base-v2)) embedding model. It's a rather *small* embedding model (109M --109 millions-- parameters) hosted on [HuggingFace](https://huggingface.co/). It converts any input text into a vector of 768 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbd57d-beee-48d6-9a20-b811d43a0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a590016-3e09-494f-b5de-cce016958829",
   "metadata": {},
   "source": [
    "The first time the model is called, it will be downloaded locally. This can take some time and disk space (about 419 MB). By default, models are stored in `$HOME/.cache/huggingface/`.\n",
    "\n",
    "If you're using university computers, to avoid overloading your HOME directory and also the NFS server that supports it, we will store models are locally in the `/tmp` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f1ad0-9d93-4e37-bf8f-0b13e5624de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "username = os.environ[\"USER\"]\n",
    "hostname = socket.gethostname()\n",
    "print(f\"This code is running on computer {hostname} with user {username}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee82873-6a19-4919-96f1-3ccf9d5451aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hostname.startswith(\"lk\"):\n",
    "    # University computers\n",
    "    model = SentenceTransformer(\n",
    "        model_name,\n",
    "        cache_folder=f\"/tmp/{username}/huggingface/hub\"\n",
    "    )\n",
    "else:\n",
    "    # Personal computers\n",
    "    model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0273e-c6b0-4a20-a2f7-79b1ca1a2ab2",
   "metadata": {},
   "source": [
    "This is the kind of output you could expect to get while downloading the model:\n",
    "\n",
    "```\n",
    "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]\n",
    "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]\n",
    "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]\n",
    "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]\n",
    "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]\n",
    "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]\n",
    "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]\n",
    "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]\n",
    "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]\n",
    "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]\n",
    "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40fda6-e8ab-4105-b91a-4a4e2b129e3f",
   "metadata": {},
   "source": [
    "### Basic example\n",
    "\n",
    "Here is a couple of sentences to play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c242db-f361-4e74-853c-1b485fe03a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"DNA carries genetic information in cells.\",\n",
    "    \"Proteins are made up of chains of amino acids.\",\n",
    "    \"DNA encodes the sequence of residues.\",\n",
    "    \"RNA is a type of nucleic acid.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b0484-868a-40a0-8f7d-a6721bf88bdc",
   "metadata": {},
   "source": [
    "We get the embeddings for each sentence. Each embedding is a vector of 768 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df89075-4557-49b3-99b4-45ac66de1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "print(\"Size of the first vector:\")\n",
    "print(len(embeddings[0]))\n",
    "print(\"Ten first elements of the first vector:\")\n",
    "print(embeddings[0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aeb464-60a7-4708-8ec4-e981c7c80d80",
   "metadata": {},
   "source": [
    "Get similarity between all embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99dbbe6-1515-490c-84a2-c66de443fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16acb06b-57d0-4c95-8b3c-f5f06b7a02d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T14:31:47.126921Z",
     "iopub.status.busy": "2024-10-22T14:31:47.126459Z",
     "iopub.status.idle": "2024-10-22T14:31:47.131221Z",
     "shell.execute_reply": "2024-10-22T14:31:47.130565Z",
     "shell.execute_reply.started": "2024-10-22T14:31:47.126892Z"
    }
   },
   "source": [
    "We obtain a 4 x 4 square matrix. The diagonal is made of 1 because a sentence is identical to itself.\n",
    "\n",
    "Remark: This code also works to get similarities based on the cosin distance\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "similarities = np.inner(embeddings, embeddings)\n",
    "```\n",
    "\n",
    "We now display the most similar sentence for a given sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21f3e1-31dd-4edb-84c2-0a70c5d3a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Discard similarity for the sentence itself.\n",
    "    # Score of 1 is remplaced by -1.\n",
    "    similarities[idx][idx] = -1\n",
    "    # Find index of the most similar sentence.\n",
    "    most_similar_idx = np.argmax(similarities[idx])\n",
    "    print(f\"Original sentence    : {sentence}\")\n",
    "    print(f\"Most similar sentence: {sentences[most_similar_idx]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19398170-95ab-412b-9fea-0b39dfab1213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T15:04:19.020335Z",
     "iopub.status.busy": "2024-10-22T15:04:19.019019Z",
     "iopub.status.idle": "2024-10-22T15:04:19.027184Z",
     "shell.execute_reply": "2024-10-22T15:04:19.026374Z",
     "shell.execute_reply.started": "2024-10-22T15:04:19.020296Z"
    }
   },
   "source": [
    "What do you think of these results? Do you agree with the most similar sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382df048-32fd-4aea-89ec-a73452e277dc",
   "metadata": {},
   "source": [
    "### Try by yourself\n",
    "\n",
    "Use different sentences and compare similarities between same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26acff-00fe-4768-8371-28d058138687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583673e0-0166-4c32-8e1a-97ffd327b89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b5f76-b438-48ce-8688-5fe1bfc4f036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f249a7c-72ed-4cb4-9706-be75769b5569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26f53c-615c-42f7-9ac1-16469e6d9876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dce5ed8-0171-4727-a23a-ca0141c37474",
   "metadata": {},
   "source": [
    "### Other models\n",
    "\n",
    "The `all-mpnet-base-v2` model takes a maximum of 384 tokens as input.\n",
    "\n",
    "Larger embedding models are openly available, such as [Alibaba-NLP/gte-Qwen2-1.5B-instruct](https://huggingface.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct):\n",
    "- 1.78B -- billions -- parameters (about 7 GB of data model to download)\n",
    "- embedding vector with 1,536 dimensions\n",
    "- max input tokens: 32k\n",
    "\n",
    "**If you want to use this more powerful model, be aware it will take some time to download on your machine.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a259fc-c84d-429d-9b4e-4bc7e9fefae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-22T15:41:47.749942Z",
     "iopub.status.busy": "2024-10-22T15:41:47.749212Z",
     "iopub.status.idle": "2024-10-22T15:43:01.334228Z",
     "shell.execute_reply": "2024-10-22T15:43:01.333584Z",
     "shell.execute_reply.started": "2024-10-22T15:41:47.749883Z"
    }
   },
   "source": [
    "For comparison, here is a list of commercial embedding models provided by [OpenAI](https://openai.com/api/pricing/):\n",
    "\n",
    "\n",
    "| Model                    | Description                                                                       | Max token | Output Dimension | Price ($US / 1M tokens) |\n",
    "| ------------------------ | --------------------------------------------------------------------------------- | --------- | ---------------- | ---------------------- |\n",
    "| `text-embedding-3-large` | Most capable embedding model for both english and non-english tasks               | 8191      | 3,072            | 0.13                   |\n",
    "| `text-embedding-3-small` | Increased performance over 2nd generation ada embedding model                     | 8191      | 1,536            | 0.02                   |\n",
    "| `text-embedding-ada-002` | Most capable 2nd generation embedding model, replacing 16 first generation models | 8191      | 1,536            | 0.10                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403dda5b-0935-4459-83a1-e68e00ed3616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
